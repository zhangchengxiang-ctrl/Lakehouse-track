# ============================================================
# Lakehouse-track：埋点全链路 + CDC（统一架构）
# 用法：docker compose up -d --build --scale collection=2
#
# 双链路架构：
#   埋点采集：SDK → HAProxy LB → [Nginx+Vector+MetaSync] x N → S3 (TSV.gz) → StarRocks Pipe
#   CDC 入湖：PostgreSQL → Flink CDC → Paimon → StarRocks Paimon Catalog
#
# 前置准备：
#   1. bash scripts/lakehouse.sh install
#   2. docker compose up -d --build --scale collection=2
#   3. StarRocks 就绪后：mysql -h 127.0.0.1 -P 9030 -u root < starrocks/starrocks.sql
#   4. Flink CDC：./scripts/lakehouse.sh run-sql flink
# ============================================================

services:
  # ==================== 基础设施 ====================
  postgres:
    image: postgres:16
    command: ["postgres", "-c", "wal_level=logical"]   # CDC 必需
    mem_limit: 512m
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: paimon
      POSTGRES_PASSWORD: paimon123
      POSTGRES_DB: paimon_db
    volumes:
      - ./data/postgres:/var/lib/postgresql/data
      - ./postgres/init:/docker-entrypoint-initdb.d:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U paimon -d paimon_db"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - lakehouse-net

  minio:
    image: minio/minio:latest
    command: server /data --console-address ":9001"
    mem_limit: 512m
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - ./data/minio:/data
    networks:
      - lakehouse-net

  minio-init:
    image: minio/mc
    depends_on:
      minio:
        condition: service_started
    entrypoint: >
      /bin/sh -c "
      for i in $$(seq 1 30); do
        /usr/bin/mc alias set myminio http://minio:9000 minioadmin minioadmin && break;
        sleep 2;
      done;
      /usr/bin/mc mb myminio/lakehouse || true;
      printf '' | /usr/bin/mc pipe myminio/lakehouse/track/events/.keep || true;
      printf '' | /usr/bin/mc pipe myminio/lakehouse/track/id_mapping/.keep || true;
      printf '' | /usr/bin/mc pipe myminio/lakehouse/paimon_data/.keep || true;
      exit 0;
      "
    networks:
      - lakehouse-net

  # ==================== 埋点采集链路 ====================
  # SDK → HAProxy → Collection (Nginx+Vector+MetaSync) → S3 → StarRocks

  # L4 负载均衡
  lb:
    image: haproxy:2.9-alpine
    mem_limit: 128m
    ports:
      - "80:80"
      - "8404:8404"          # HAProxy 统计页面
    volumes:
      - ./haproxy/haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro
    depends_on:
      - collection
    restart: on-failure
    networks:
      - lakehouse-net

  # 采集节点 (Nginx + Vector + MetaSync)，无状态可水平扩展
  collection:
    build:
      context: .
      dockerfile: collection/Dockerfile
    mem_limit: 1g
    environment:
      PG_HOST: postgres
      PG_PORT: "5432"
      PG_USER: paimon
      PG_PASSWORD: paimon123
      PG_DB: paimon_db
      S3_ENDPOINT: "http://minio:9000"
      S3_ACCESS_KEY: minioadmin
      S3_SECRET_KEY: minioadmin
      S3_BUCKET: lakehouse
      S3_REGION: us-east-1
      META_API_URL: "http://meta-api:3000/register"
      META_SYNC_INTERVAL: "30"
    volumes:
      - ./collection/config/geoip:/etc/vector/geoip:ro
      - ./collection/config/sdk_debug:/etc/nginx/sdk_debug:ro
    depends_on:
      postgres:
        condition: service_healthy
      minio:
        condition: service_started
    restart: on-failure
    networks:
      - lakehouse-net

  # 元数据注册 API
  meta-api:
    build:
      context: .
      dockerfile: meta-api/Dockerfile
    mem_limit: 256m
    ports:
      - "3000:3000"
    environment:
      PG_HOST: postgres
      PG_PORT: "5432"
      PG_USER: paimon
      PG_PASSWORD: paimon123
      PG_DB: paimon_db
      PG_POOL_MAX: "20"
    depends_on:
      postgres:
        condition: service_healthy
    restart: on-failure
    networks:
      - lakehouse-net

  # ==================== CDC 链路 (Flink + Paimon) ====================
  # PostgreSQL CDC → Flink → Paimon → StarRocks Paimon Catalog

  flink-jobmanager:
    build:
      context: .
      dockerfile: flink/Dockerfile
    container_name: flink-jobmanager
    hostname: flink-jobmanager
    command: jobmanager
    mem_limit: 2g
    volumes:
      - ./flink/flink.sql:/opt/flink/flink.sql:ro
    environment:
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
      - ENABLE_S3_PATH_STYLE_ACCESS=true
      - "FLINK_PROPERTIES=jobmanager.rpc.address: flink-jobmanager"
    ports:
      - "8081:8081"
    depends_on:
      postgres:
        condition: service_healthy
      minio:
        condition: service_started
      hive-metastore:
        condition: service_started
    networks:
      - lakehouse-net

  flink-taskmanager:
    build:
      context: .
      dockerfile: flink/Dockerfile
    container_name: flink-taskmanager
    hostname: flink-taskmanager
    command: taskmanager
    mem_limit: 2g
    environment:
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
      - ENABLE_S3_PATH_STYLE_ACCESS=true
      - "FLINK_PROPERTIES=jobmanager.rpc.address: flink-jobmanager"
    depends_on:
      - flink-jobmanager
    networks:
      - lakehouse-net

  hive-metastore:
    image: apache/hive:3.1.3
    container_name: hive-metastore
    user: "0:0"
    restart: on-failure
    entrypoint: ["/bin/sh", "-c"]
    command: "/opt/hive/bin/hms-entrypoint.sh"
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      - HIVE_CONF_hive_metastore_warehouse_dir=s3a://lakehouse/paimon_data/
      - HIVE_CONF_hive_metastore_disallow_incompatible_col_type_changes=false
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
      - SERVICE_NAME=metastore
      - DB_DRIVER=postgres
      - >-
        SERVICE_OPTS=-Djavax.jdo.option.ConnectionURL=jdbc:postgresql://postgres:5432/metastore
        -Djavax.jdo.option.ConnectionDriverName=org.postgresql.Driver
        -Djavax.jdo.option.ConnectionUserName=paimon
        -Djavax.jdo.option.ConnectionPassword=paimon123
    ports:
      - "9083:9083"
    volumes:
      - ./flink/lib/postgresql-42.7.3.jar:/opt/hive/lib/postgresql-42.7.3.jar
      - ./hive/lib/hadoop-aws-3.1.0.jar:/opt/hive/lib/hadoop-aws-3.1.0.jar
      - ./hive/lib/aws-java-sdk-bundle-1.11.271.jar:/opt/hive/lib/aws-java-sdk-bundle-1.11.271.jar
      - ./hive/hive-site.xml:/opt/hive/conf/hive-site.xml:ro
      - ./hive/hms-entrypoint.sh:/opt/hive/bin/hms-entrypoint.sh:ro
    networks:
      - lakehouse-net

  # ==================== 分析层 (StarRocks 存算分离) ====================

  starrocks-fe:
    image: starrocks/fe-ubuntu:3.5.12
    container_name: starrocks-fe
    hostname: starrocks-fe
    mem_limit: 4g
    environment:
      - HOST_TYPE=FQDN
      - JAVA_TOOL_OPTIONS=--add-opens=java.base/java.util=ALL-UNNAMED
    command:
      - /bin/bash
      - -c
      - |
        mkdir -p /opt/starrocks/fe/lib/paimon-ext
        if [ -d /opt/starrocks-extra-jars ] && ls /opt/starrocks-extra-jars/*.jar 1>/dev/null 2>&1; then
          ln -sf /opt/starrocks-extra-jars/*.jar /opt/starrocks/fe/lib/paimon-ext/
        fi
        if ! grep -q "BEGIN LAKEHOUSE_TRACK_SHARED_CONF" /opt/starrocks/fe/conf/fe.conf 2>/dev/null; then
          {
            echo ""
            echo "# BEGIN LAKEHOUSE_TRACK_SHARED_CONF"
            cat /opt/starrocks-fe-shared.conf
            echo "# END LAKEHOUSE_TRACK_SHARED_CONF"
          } >> /opt/starrocks/fe/conf/fe.conf
        fi
        /opt/starrocks/fe/bin/start_fe.sh
    ports:
      - "8030:8030"
      - "9020:9020"
      - "9030:9030"
    volumes:
      - ./starrocks/config/fe-shared.conf:/opt/starrocks-fe-shared.conf:ro
      - ./starrocks/jars:/opt/starrocks-extra-jars:ro
      - ./data/starrocks/fe:/opt/starrocks/fe/meta
    healthcheck:
      test: ["CMD-SHELL", "mysql -uroot -h127.0.0.1 -P9030 -e 'SELECT 1'"]
      interval: 15s
      timeout: 10s
      retries: 10
      start_period: 120s
    depends_on:
      minio:
        condition: service_started
    networks:
      - lakehouse-net

  starrocks-cn:
    image: starrocks/cn-ubuntu:3.5.12
    container_name: starrocks-cn
    hostname: starrocks-cn
    mem_limit: 4g
    environment:
      - HOST_TYPE=FQDN
      - JAVA_TOOL_OPTIONS=--add-opens=java.base/java.util=ALL-UNNAMED
    command:
      - /bin/bash
      - -c
      - |
        # 注入 CN 缓存配置（追加到 cn.conf 末尾）
        if [ -f /opt/starrocks-cn-shared.conf ] && ! grep -q "LAKEHOUSE_TRACK_CN_CONF" /opt/starrocks/cn/conf/cn.conf 2>/dev/null; then
          {
            echo ""
            echo "# BEGIN LAKEHOUSE_TRACK_CN_CONF"
            cat /opt/starrocks-cn-shared.conf
            echo "# END LAKEHOUSE_TRACK_CN_CONF"
          } >> /opt/starrocks/cn/conf/cn.conf
        fi
        mkdir -p /opt/starrocks/cn/lib/paimon-ext /opt/starrocks/cn/datacache
        if [ -d /opt/starrocks-extra-jars ] && ls /opt/starrocks-extra-jars/*.jar 1>/dev/null 2>&1; then
          ln -sf /opt/starrocks-extra-jars/*.jar /opt/starrocks/cn/lib/paimon-ext/
        fi
        sleep 15
        mysql -h starrocks-fe -P9030 -uroot -e "SHOW COMPUTE NODES" | grep -q "starrocks-cn" || \
        mysql -h starrocks-fe -P9030 -uroot -e "ALTER SYSTEM ADD COMPUTE NODE 'starrocks-cn:9050';"
        /opt/starrocks/cn/bin/start_cn.sh
    ports:
      - "8040:8040"
    volumes:
      - ./starrocks/config/cn.conf:/opt/starrocks-cn-shared.conf:ro
      - ./starrocks/jars:/opt/starrocks-extra-jars:ro
      - ./data/starrocks/cn/storage:/opt/starrocks/cn/storage
      - ./data/starrocks/cn/datacache:/opt/starrocks/cn/datacache
    depends_on:
      starrocks-fe:
        condition: service_healthy
      minio:
        condition: service_started
    healthcheck:
      test: ["CMD-SHELL", "mysql -uroot -hstarrocks-fe -P9030 -e 'SHOW COMPUTE NODES' | grep 'starrocks-cn' | grep -q '1'"]
      interval: 15s
      timeout: 10s
      retries: 10
      start_period: 180s
    restart: on-failure
    networks:
      - lakehouse-net

networks:
  lakehouse-net:
    name: lakehouse-net
    driver: bridge
